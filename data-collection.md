# Data

## Collecting

### Web scraping

To scrape the web, you're going to have to parse the DOM some way.

* If you're dealing with fairly static pages, [Cheerio](https://cheerio.js.org/) is great. It's light-weight and easy to use.
* For more complicated tasks where you either need to interact with the page, or there is dynamic content you need access to, [Puppeteer](https://pptr.dev/) is probably your best bet.

## Analysing

There are a million and one tools for analysing data and the right tool depends a lot on the job, and on your own experience.

* [Jupyter](https://jupyter.org/) notebooks are a great tool for analysing data with added analysis and narrative.
* You can author and store Jupyter notebooks in your Google Drive with [Colaboratory](https://colab.research.google.com/).
* [Knime](https://www.knime.com/) is a pretty amazing, if somewhat clunky tool which is great for doing data science type things \(especially [text analytics](https://www.knime.com/knime-text-processing)\) and automating workflows for reproducibility. Just [ask Angus Veitch](https://twitter.com/AngusVeitch/status/1093658731202543616), who did his whole PhD using Knime.

